include "../../../arch/x64/Vale.X64.InsBasic.vaf"
include "../../../arch/x64/Vale.X64.InsVector.vaf"
include "../../../arch/x64/Vale.X64.InsAes.vaf"
include{:fstar}{:open} "Vale.Def.Types_s"
include{:fstar}{:open} "Vale.Arch.Types"
include{:fstar}{:open} "Vale.Math.Poly2_s"
include{:fstar}{:open} "Vale.Math.Poly2"
include{:fstar}{:open} "Vale.Math.Poly2.Bits_s"
include{:fstar}{:open} "Vale.Math.Poly2.Bits"
include{:fstar}{:open} "Vale.Math.Poly2.Words"
include{:fstar}{:open} "Vale.Math.Poly2.Lemmas"
include{:fstar}{:open} "Vale.AES.GF128_s"
include{:fstar}{:open} "Vale.AES.GF128"
include{:fstar}{:open} "Vale.X64.Machine_s"
include{:fstar}{:open} "Vale.X64.State"
include{:fstar}{:open} "Vale.X64.Decls"
include{:fstar}{:open} "Vale.X64.QuickCode"
include{:fstar}{:open} "Vale.X64.QuickCodes"
include{:fstar}{:open} "Vale.X64.CPU_Features_s"

module Vale.AES.X64.GF128_Mul

#verbatim{:interface}{:implementation}
open Vale.Def.Types_s
open Vale.Arch.Types
open Vale.Math.Poly2_s
open Vale.Math.Poly2
open Vale.Math.Poly2.Bits_s
open Vale.Math.Poly2.Bits
open Vale.Math.Poly2.Lemmas
open Vale.AES.GF128_s
open Vale.AES.GF128
open Vale.X64.Machine_s
open Vale.X64.State
open Vale.X64.Decls
open Vale.X64.InsBasic
open Vale.X64.InsMem
open Vale.X64.InsVector
open Vale.X64.InsAes
open Vale.X64.QuickCode
open Vale.X64.QuickCodes
open Vale.X64.CPU_Features_s
#endverbatim

procedure ShiftLeft128_1(ghost a:poly)
    {:public}
    {:quick}
    modifies
        efl;
        xmm1; xmm2;
    requires
        avx_enabled;
        sse_enabled;
        degree(a) < 128;
        xmm1 == to_quad32(a);
    ensures
        xmm1 == to_quad32(shift(a, 1));
{
    Mov128(xmm2, xmm1);
    Psrld(xmm2, 31);
    Pslld(xmm1, 1);
    VPslldq4(xmm2, xmm2);
    Pxor(xmm1, xmm2);

    lemma_shift_left_1(a);
}

procedure ShiftLeft2_128_1(ghost lo:poly, ghost hi:poly)
    {:quick}
    modifies
        efl; r12;
        xmm1; xmm2; xmm3; xmm4; xmm5;
    requires
        avx_enabled;
        sse_enabled;
        degree(hi) < 127;
        degree(lo) <= 127;
        xmm1 == to_quad32(lo);
        xmm2 == to_quad32(hi);
    ensures
        let n := monomial(128);
        let a := add(mul(hi, n), lo);
        let b := shift(a, 1);
        xmm1 == to_quad32(mod(b, n));
        xmm2 == to_quad32(div(b, n));
{
    // qa := xmm1
    // qb := xmm2

    // ra := map(>> 31)(qa)
    Mov128(xmm3, xmm1);
    Psrld(xmm3, 31);

    // rb := map(>> 31)(qb)
    Mov128(xmm4, xmm2);
    Psrld(xmm4, 31);

    // la := map(<< 1)(qa)
    // lb := map(<< 1)(qb)
    Pslld(xmm1, 1);
    Pslld(xmm2, 1);

    // ra012 := ra << 32
    // rb012 := rb << 32
    VPslldq4(xmm5, xmm3);
    VPslldq4(xmm4, xmm4);

    // ra3 := ra >> 96
    PinsrdImm(xmm3, 0, 0, r12);
    Pshufd(xmm3, xmm3, 0x03); // (hi) 0 0 0 3 (lo)

    // ra3_rb012 := ra3 + rb012
    Pxor(xmm3, xmm4);

    // qa' := la + ra012
    // qb' := lb + ra3_rb012
    Pxor(xmm1, xmm5);
    Pxor(xmm2, xmm3);

    lemma_shift_2_left_1(lo, hi);
}

procedure ClmulRev64(ghost a:poly, ghost b:poly, inline dstHi:bool, inline srcHi:bool)
    {:quick}
    reads
    modifies
        efl;
        xmm1; xmm2;
    requires
        pclmulqdq_enabled && avx_enabled && sse_enabled;
        degree(a) <= 63;
        degree(b) <= 63;
        reverse(a, 63) == of_double32(if dstHi then quad32_double_hi(xmm1) else quad32_double_lo(xmm1));
        reverse(b, 63) == of_double32(if srcHi then quad32_double_hi(xmm2) else quad32_double_lo(xmm2));
    ensures
        xmm1 == to_quad32(reverse(mul(a, b), 127));
{
    Pclmulqdq(xmm1, xmm2, dstHi, srcHi);
    ShiftLeft128_1(mul(reverse(a, 63), reverse(b, 63)));

    lemma_mul_reverse_shift_1(a, b, 63);
}

procedure High64ToLow(out dst:xmm, ghost a:poly)
    {:quick exportOnly}
    modifies
        efl; r12;
    requires
        sse_enabled;
        degree(a) <= 127;
        dst == to_quad32(a);
    ensures
        dst == to_quad32(div(a, monomial(64)));
{
    PinsrdImm(dst, 0, 0, r12);
    Pshufd(dst, dst, 0x0e); // (hi) 0 0 3 2 (lo)
    lemma_quad32_double_shift(a);
}

procedure Low64ToHigh(out dst:xmm, ghost a:poly)
    {:quick exportOnly}
    modifies
        efl; r12;
    requires
        sse_enabled;
        degree(a) <= 127;
        dst == to_quad32(a);
    ensures
        dst == to_quad32(mul(mod(a, monomial(64)), monomial(64)));
{
    PinsrdImm(dst, 0, 3, r12);
    Pshufd(dst, dst, 0x4f); // (hi) 1 0 3 3 (lo)
    lemma_quad32_double_shift(a);
}

procedure AddPoly(out dst:xmm, in src:xmm, ghost a:poly, ghost b:poly)
    {:quick exportOnly}
    modifies
        efl;
    requires
        sse_enabled;
        degree(a) <= 127;
        degree(b) <= 127;
        dst == to_quad32(a);
        src == to_quad32(b);
    ensures
        dst == to_quad32(add(a, b));
{
    Pxor(dst, src);
    lemma_add128(a, b);
}

procedure Clmul128(ghost ab:poly, ghost cd:poly) returns(ghost lo:poly, ghost hi:poly)
    {:quick}
    modifies
        efl; r12;
        xmm1; xmm2; xmm3; xmm4; xmm5;
    requires
        pclmulqdq_enabled && sse_enabled;
        degree(ab) <= 127;
        degree(cd) <= 127;
        xmm1 == to_quad32(ab);
        xmm2 == to_quad32(cd);
    ensures
        degree(lo) <= 127;
        degree(hi) < 127;
        mul(ab, cd) == add(shift(hi, 128), lo);
        xmm1 == to_quad32(lo);
        xmm2 == to_quad32(hi);
{
    let n := monomial(64);
    let a := div(ab, n);
    let b := mod(ab, n);
    let c := div(cd, n);
    let d := mod(cd, n);
    let ac := mul(a, c);
    let ad := mul(a, d);
    let bc := mul(b, c);
    let bd := mul(b, d);
    lemma_div_mod(ab, n);
    lemma_quad32_double(ab);
    lemma_quad32_double(cd);

    Mov128(xmm5, xmm1);

    // xmm3 := bc
    Pclmulqdq(xmm1, xmm2, false, true);
    Mov128(xmm3, xmm1);

    // xmm4 := ad
    Mov128(xmm1, xmm5);
    Pclmulqdq(xmm1, xmm2, true, false);
    Mov128(xmm4, xmm1);

    // xmm1 := bd
    Mov128(xmm1, xmm5);
    Pclmulqdq(xmm1, xmm2, false, false);

    // xmm5 := ac
    Pclmulqdq(xmm5, xmm2, true, true);

    // xmm2 := ac + hi(bc) + hi(ad)
    Mov128(xmm2, xmm5); // ac
    Mov128(xmm5, xmm1); // bd
    Mov128(xmm1, xmm3); // bc
    High64ToLow(xmm1, bc);
    AddPoly(xmm2, xmm1, ac, div(bc, n));
    Mov128(xmm1, xmm4); // ad
    High64ToLow(xmm1, ad);
    AddPoly(xmm2, xmm1, add(ac, div(bc, n)), div(ad, n));

    // xmm1 := lo(bc) * n + lo(ad) * n + bd
    Mov128(xmm1, xmm3); // bc
    Low64ToHigh(xmm1, bc);
    Low64ToHigh(xmm4, ad);
    AddPoly(xmm1, xmm4, mul(mod(bc, n), n), mul(mod(ad, n), n));
    AddPoly(xmm1, xmm5, add(mul(mod(bc, n), n), mul(mod(ad, n), n)), bd);

    hi := add(add(ac, div(bc, n)), div(ad, n));
    lo := add(add(mul(mod(bc, n), n), mul(mod(ad, n), n)), bd);
    lemma_gf128_mul(a, b, c, d, 64);
}

procedure ClmulRev128(ghost ab:poly, ghost cd:poly) returns(ghost lo:poly, ghost hi:poly)
    {:quick}
    modifies
        efl; r12;
        xmm1; xmm2; xmm3; xmm4; xmm5;
    requires
        pclmulqdq_enabled && avx_enabled && sse_enabled;
        degree(ab) <= 127;
        degree(cd) <= 127;
        xmm1 == to_quad32(reverse(ab, 127));
        xmm2 == to_quad32(reverse(cd, 127));
    ensures
        degree(lo) <= 127;
        degree(hi) <= 127;
        reverse(mul(ab, cd), 255) == add(shift(hi, 128), lo);
        xmm1 == to_quad32(lo);
        xmm2 == to_quad32(hi);
{
    lo, hi := Clmul128(reverse(ab, 127), reverse(cd, 127));
    ShiftLeft2_128_1(lo, hi);

    let m := shift(add(shift(hi, 128), lo), 1);
    lemma_combine_define(hi, lo, 128);
    lemma_split_define(m, 128);
    lo := mod(m, monomial(128));
    hi := div(m, monomial(128));
    lemma_mul_reverse_shift_1(ab, cd, 127);
}

procedure Gf128ModulusRev(inout dst:xmm)
    {:quick exportOnly}
    modifies
        efl; r12;
    requires sse_enabled;
    ensures
        dst == to_quad32(reverse(gf128_modulus_low_terms, 127));
{
    lemma_gf128_constant_rev(dst);
    Pxor(dst, dst);
    PinsrdImm(dst, 0xe100_0000, 3, r12);
}

procedure ReduceMulRev128(ghost a:poly, ghost b:poly)
    {:public}
    {:quick}
    modifies
        efl; r12;
        xmm1; xmm2; xmm3; xmm4; xmm5; xmm6;
    requires
        pclmulqdq_enabled && avx_enabled && sse_enabled;
        degree(a) <= 127;
        degree(b) <= 127;
        xmm1 == to_quad32(reverse(a, 127));
        xmm2 == to_quad32(reverse(b, 127));
    ensures
        xmm1 == to_quad32(reverse(gf128_mul(a, b), 127));
{
    lemma_gf128_degree();
    lemma_gf128_reduce_rev(a, b, gf128_modulus_low_terms, 128);
    let m := monomial(128);
    let h := gf128_modulus_low_terms;
    let ab := mul(a, b);
    let rh := reverse(h, 127);
    let rab := reverse(ab, 255);
    let rd := mod(rab, m);
    let rdh := reverse(mul(reverse(rd, 127), h), 255);
    let rdhL := mod(rdh, m);
    let rdhLh := reverse(mul(reverse(rdhL, 127), h), 127);

    let (lo1, hi1) := ClmulRev128(a, b);
    lemma_combine_define(hi1, lo1, 128);
    Mov128(xmm6, xmm2); // div(rab, m);

    Gf128ModulusRev(xmm2);
    // REVIEW: h is small, so we could make a more efficient version of ClmulRev128 for this:
    let (lo2, hi2) := ClmulRev128(reverse(rd, 127), h);
    lemma_combine_define(hi2, lo2, 128);
    Mov128(xmm5, xmm2); // div(rdh, m);

    Gf128ModulusRev(xmm2);

    lemma_quad32_double_hi_rev(rdhL);
    lemma_quad32_double_hi_rev(rh);
    ClmulRev64(reverse(rdhL, 127), h, true, true);

    AddPoly(xmm1, xmm5, rdhLh, div(rdh, m));
    AddPoly(xmm1, xmm6, add(rdhLh, div(rdh, m)), div(rab, m));
}

procedure Gf128MulRev128()
    {:public}
    {:quick}
    lets
        a := of_quad32(xmm1);
        b := of_quad32(xmm2);
    modifies
        efl; r12;
        xmm1; xmm2; xmm3; xmm4; xmm5; xmm6;
    requires
        pclmulqdq_enabled && avx_enabled && sse_enabled;
    ensures
        of_quad32(xmm1) == gf128_mul_rev(a, b);
{
    ReduceMulRev128(reverse(a, 127), reverse(b, 127));
    lemma_of_to_quad32(gf128_mul_rev(a, b));
}

